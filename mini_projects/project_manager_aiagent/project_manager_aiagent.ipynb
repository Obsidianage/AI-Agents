{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, START,END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import Image, display, Markdown, HTML\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from typing import Optional, List, Union\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"groq_api_key\"] =  os.getenv('groq_api_key')\n",
    "\n",
    "# note only few selected models are only compatible with with_structured_output() method\n",
    "# and we are using groq model here which is compatible\n",
    "llm = ChatGroq(\n",
    "    groq_api_key=os.getenv('groq_api_key'), model_name=\"Gemma2-9b-It\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.invoke(\"check: working? Not working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Classes\n",
    "**State Management**\n",
    "1. AgentState \n",
    "    - project description\n",
    "    - team\n",
    "    - tasks\n",
    "    - dependencies\n",
    "    - schedule\n",
    "    - task_allocations\n",
    "    - risks \n",
    "    - iteration_number\n",
    "    - max_iteration\n",
    "    - insights\n",
    "    - schedule_iteration\n",
    "    - task_allocations_iteration\n",
    "    - risks_iteration\n",
    "    - project_risk_score_iterations\n",
    "\n",
    "2. Task\n",
    "    - id\n",
    "    - task_name\n",
    "    - taks_description\n",
    "    - estimated_day\n",
    "3. TaskDependency\n",
    "4. Team Member\n",
    "5. Team\n",
    "6. TaskAllocation\n",
    "7. TaskSchedule\n",
    "8. TaskList\n",
    "9. DependencyList\n",
    "10. Schedule\n",
    "11. TaskAllocationList\n",
    "12. Risk\n",
    "13. RiskList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data classes\n",
    "- agent state\n",
    "- nodes and functions (used as a router)\n",
    "- workflow of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Models\n",
    "class Task(BaseModel):\n",
    "    \"\"\"Task model for project management\"\"\"\n",
    "    id: uuid.UUID = Field(default_factory=uuid.uuid4, description=\"Unique identifier for the task\")\n",
    "    task_name: str = Field(description=\"Name of the task\")\n",
    "    description: str = Field(description=\"Description of the task\")\n",
    "    estimated_day: int = Field(description=\"Estimated number of days to complete the task\")\n",
    "\n",
    "\n",
    "class TaskList(BaseModel):\n",
    "    \"\"\"List of project tasks\"\"\"\n",
    "    tasks: List[Task] = Field(description=\"List of tasks\")\n",
    "\n",
    "class TaskDependency(BaseModel):\n",
    "    \"\"\"Task dependency model\"\"\"\n",
    "    task: Task = Field(description=\"Task\")\n",
    "    dependent_task:List[Task] = Field(description=\"List of dependent tasks\")\n",
    "\n",
    "class TeamMember(BaseModel):\n",
    "    name: str = Field(description=\"Name of the team member\")\n",
    "    profile: str = Field(description=\"Profile of the team member\")\n",
    "\n",
    "class Team(BaseModel):\n",
    "    team_members: List[TeamMember] = Field(description=\"List of team members\")\n",
    "\n",
    "class TaskAllocation(BaseModel):\n",
    "    \"\"\"Task allocation class\"\"\"\n",
    "    task: Task = Field(description=\"Task\")\n",
    "    team_member: TeamMember = Field(description=\"Team members assigned to the task\")\n",
    "\n",
    "class TaskSchedule(BaseModel):\n",
    "    \"\"\"Schedule schedule class\"\"\"\n",
    "    task: Task = Field(description=\"Task\")\n",
    "    start_day: int = Field(description=\"Start day of the task\")\n",
    "    end_day: int = Field(description=\"End day of the task\")\n",
    "\n",
    "class DependencyList(BaseModel):\n",
    "    \"\"\"List of task dependencies\"\"\"\n",
    "    dependencies: List[TaskDependency] = Field(description=\"List of task dependencies\")\n",
    "\n",
    "class Schedule(BaseModel):\n",
    "    \"\"\"List of task schedules\"\"\"\n",
    "    schedule: List[TaskSchedule] = Field(description=\"List of task schedules\")\n",
    "\n",
    "class TaskAllocationList(BaseModel):\n",
    "    \"\"\"List of task allocations\"\"\"\n",
    "    task_allocations: List[TaskAllocation] = Field(description=\"List of task allocations\")\n",
    "\n",
    "class TaskAllocationListIteration(BaseModel):\n",
    "    \"\"\"List of task allocations for each iteration\"\"\"\n",
    "    task_allocations_iteration: List[TaskAllocationList] = Field(description=\"List of task allocations for each iteration\")\n",
    "\n",
    "class ScheduleIteration(BaseModel):\n",
    "    \"\"\"List of task schedules for each iteration\"\"\"\n",
    "    schedule: List[Schedule] = Field(description=\"List of task schedules for each iteration\")\n",
    "\n",
    "class Risk(BaseModel):\n",
    "    \"\"\"Risk of a task\"\"\"\n",
    "    task: Task = Field(description=\"Task\")\n",
    "    score: str = Field(description=\"Risk associated with the task\")\n",
    "\n",
    "class RiskList(BaseModel):\n",
    "    \"\"\"List of risks for each iteration\"\"\"\n",
    "    risks: List[Risk] = Field(description=\"List of risks\")\n",
    "\n",
    "class RiskListIteration(BaseModel):\n",
    "    \"\"\"List of risks for each iteration\"\"\"\n",
    "    risks_iteration: List[RiskList] = Field(description=\"List of risks for each iteration\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AgentState creation. \n",
    "- schedule_iteration, task_allocations_iteration, risks_iteration to generate structured memory for the self_reflection cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"Project Manager Agent State\"\"\"\n",
    "    project_description: str\n",
    "    team: Team\n",
    "    tasks: TaskList\n",
    "    dependencies: DependencyList\n",
    "    schedule: Schedule\n",
    "    task_allocations: TaskAllocationList\n",
    "    risks: RiskList\n",
    "    iteration_number: int\n",
    "    max_iteration: int\n",
    "    insights: List[str]\n",
    "    schedule_iteration: List[ScheduleIteration]\n",
    "    task_allocations_iteration: List[TaskAllocationListIteration]\n",
    "    risks_iteration: List[RiskListIteration]\n",
    "    project_risk_score_iterations: List[int]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_generation_node(state: AgentState):\n",
    "    \"\"\"LangGraph node that will extract tasks from given project description\"\"\"\n",
    "    description = state[\"project_description\"]\n",
    "    prompt = f\"\"\"You are an expert project manager tasked with analyzing the following project description: {description}\n",
    "    \n",
    "    Your task is to break this project into clear, actionable tasks. For each task, provide:\n",
    "    - A clear, concise name\n",
    "    - A detailed description\n",
    "    - Estimated days to complete (as a number)\n",
    "\n",
    "    Please format your response as a JSON object with the following structure:\n",
    "    {{\n",
    "        \"tasks\": [\n",
    "            {{\n",
    "                \"task_name\": \"string\",\n",
    "                \"description\": \"string\",\n",
    "                \"estimated_day\": number\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Guidelines:\n",
    "    - Each task should be specific and measurable\n",
    "    - Break down tasks that would take more than 5 days into smaller sub-tasks\n",
    "    - Estimated days should be realistic integers\n",
    "    - Task names should be brief but descriptive\n",
    "    - Descriptions should provide enough detail for implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        structure_llm = llm.with_structured_output(TaskList)\n",
    "        tasks: TaskList = structure_llm.invoke(prompt)\n",
    "        return {\"tasks\": tasks}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in task generation: {str(e)}\")\n",
    "        print(f\"Raw response from LLM: {tasks if 'tasks' in locals() else 'No response'}\")\n",
    "        return {\"tasks\": TaskList(tasks=[])}\n",
    "def task_dependency_node(state: AgentState):\n",
    "    \"\"\"LangGraph node that will identify task dependencies\"\"\"\n",
    "    tasks = state[\"tasks\"]\n",
    "    prompt = f\"\"\"You are a skilled project scheduler analyzing dependencies between tasks.\n",
    "    \n",
    "    Given these tasks: {tasks}\n",
    "\n",
    "    Create a dependency map showing which tasks must be completed before others can begin.\n",
    "    Format your response as a JSON object with this structure:\n",
    "    {{\n",
    "        \"dependencies\": [\n",
    "            {{\n",
    "                \"task\": {{\n",
    "                    \"task_name\": \"string\",\n",
    "                    \"description\": \"string\",\n",
    "                    \"estimated_day\": number,\n",
    "                    \"id\": \"uuid-string\"\n",
    "                }},\n",
    "                \"dependent_tasks\": [\n",
    "                    {{\n",
    "                        \"task_name\": \"string\",\n",
    "                        \"description\": \"string\",\n",
    "                        \"estimated_day\": number,\n",
    "                        \"id\": \"uuid-string\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Guidelines:\n",
    "    - Identify direct dependencies only\n",
    "    - Ensure no circular dependencies\n",
    "    - Consider logical sequence of work\n",
    "    - Include all task details in both task and dependent_tasks objects\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        structure_llm = llm.with_structured_output(DependencyList)\n",
    "        dependencies: DependencyList = structure_llm.invoke(prompt)\n",
    "        return {\"dependencies\": dependencies}\n",
    "    except Exception as e:\n",
    "        print(f\"Error in dependency mapping: {str(e)}\")\n",
    "        print(f\"Raw response from LLM: {dependencies if 'dependencies' in locals() else 'No response'}\")\n",
    "        return {\"dependencies\": DependencyList(dependencies=[])}\n",
    "def task_scheduler_node(state: AgentState):\n",
    "    \"\"\"LangGraph node that will schedule tasks based on dependencies\"\"\"\n",
    "    dependencies = state[\"dependencies\"]\n",
    "    tasks = state[\"tasks\"]\n",
    "    insights = state.get('insights', '')\n",
    "    previous_schedules = state.get(\"schedule_iteration\", [])\n",
    "    \n",
    "    prompt = f\"\"\"You are an experienced project scheduler creating an optimized timeline.\n",
    "    \n",
    "    Given:\n",
    "    - Tasks: {tasks}\n",
    "    - Dependencies: {dependencies}\n",
    "    - Previous Insights: {insights}\n",
    "    - Previous Schedules: {previous_schedules}\n",
    "\n",
    "    Create a schedule that assigns start and end days to each task.\n",
    "    Format your response as a JSON object with this structure:\n",
    "    {{\n",
    "        \"schedule\": [\n",
    "            {{\n",
    "                \"task\": {{\n",
    "                    \"task_name\": \"string\",\n",
    "                    \"description\": \"string\",\n",
    "                    \"estimated_day\": number,\n",
    "                    \"id\": \"uuid-string\"\n",
    "                }},\n",
    "                \"start_day\": number,\n",
    "                \"end_day\": number\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Guidelines:\n",
    "    - Respect all task dependencies\n",
    "    - Minimize total project duration\n",
    "    - Allow parallel execution where possible\n",
    "    - Ensure end_day - start_day + 1 equals estimated_day\n",
    "    - Start with day 1 (no zero days)\n",
    "    - Include complete task details in each task object\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        structure_llm = llm.with_structured_output(Schedule)\n",
    "        schedule: Schedule = structure_llm.invoke(prompt)\n",
    "        state[\"schedule\"] = schedule\n",
    "        state[\"schedule_iteration\"].append(schedule)\n",
    "        return state\n",
    "    except Exception as e:\n",
    "        print(f\"Error in scheduling: {str(e)}\")\n",
    "        print(f\"Raw response from LLM: {schedule if 'schedule' in locals() else 'No response'}\")\n",
    "        default_schedule = Schedule(schedule=[])\n",
    "        state[\"schedule\"] = default_schedule\n",
    "        state[\"schedule_iteration\"].append(default_schedule)\n",
    "        return state\n",
    "def task_allocation_node(state: AgentState):\n",
    "    \"\"\"LangGraph node that will allocate tasks to team members\"\"\"\n",
    "    tasks = state[\"tasks\"]\n",
    "    schedule = state[\"schedule\"]\n",
    "    team = state[\"team\"]\n",
    "    insights = state.get('insights', '')\n",
    "    previous_allocations = state.get(\"task_allocations_iteration\", [])\n",
    "    \n",
    "    prompt = f\"\"\"You are a project manager assigning tasks to team members optimally.\n",
    "    \n",
    "    Given:\n",
    "    - Tasks and Schedule: {schedule}\n",
    "    - Team Members: {team}\n",
    "    - Previous Insights: {insights}\n",
    "    - Previous Allocations: {previous_allocations}\n",
    "\n",
    "    Create task assignments that match team members' skills with task requirements.\n",
    "    Format your response as a JSON object with this structure:\n",
    "    {{\n",
    "        \"task_allocations\": [\n",
    "            {{\n",
    "                \"task\": {{\n",
    "                    \"task_name\": \"string\",\n",
    "                    \"description\": \"string\",\n",
    "                    \"estimated_day\": number,\n",
    "                    \"id\": \"uuid-string\"\n",
    "                }},\n",
    "                \"team_member\": {{\n",
    "                    \"name\": \"string\",\n",
    "                    \"profile\": \"string\"\n",
    "                }}\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Guidelines:\n",
    "    - Match skills to task requirements\n",
    "    - Avoid overloading team members\n",
    "    - Consider task timing from schedule\n",
    "    - Ensure all tasks are assigned\n",
    "    - Include complete task and team member details\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        structure_llm = llm.with_structured_output(TaskAllocationList)\n",
    "        allocations: TaskAllocationList = structure_llm.invoke(prompt)\n",
    "        state[\"task_allocations\"] = allocations\n",
    "        state[\"task_allocations_iteration\"].append(allocations)\n",
    "        return state\n",
    "    except Exception as e:\n",
    "        print(f\"Error in task allocation: {str(e)}\")\n",
    "        print(f\"Raw response from LLM: {allocations if 'allocations' in locals() else 'No response'}\")\n",
    "        default_allocations = TaskAllocationList(task_allocations=[])\n",
    "        state[\"task_allocations\"] = default_allocations\n",
    "        state[\"task_allocations_iteration\"].append(default_allocations)\n",
    "        return state\n",
    "def insight_generation_node(state: AgentState):\n",
    "    \"\"\"LangGraph node that generates insights from schedule, allocation, and risks\"\"\"\n",
    "    schedule = state[\"schedule\"]\n",
    "    task_allocations = state[\"task_allocations\"]\n",
    "    risks = state[\"risks\"]\n",
    "    previous_insights = state.get('insights', '')\n",
    "    \n",
    "    prompt = f\"\"\"You are a project management consultant analyzing the current project plan.\n",
    "    \n",
    "    Given:\n",
    "    - Schedule: {schedule}\n",
    "    - Task Allocations: {task_allocations}\n",
    "    - Risk Analysis: {risks}\n",
    "    - Previous Insights: {previous_insights}\n",
    "\n",
    "    Analyze the project plan and provide actionable insights.\n",
    "    Focus on:\n",
    "    1. Potential bottlenecks or conflicts\n",
    "    2. Resource utilization issues\n",
    "    3. Risk mitigation strategies\n",
    "    4. Optimization opportunities\n",
    "    5. Specific recommendations for improvement\n",
    "\n",
    "    Guidelines:\n",
    "    - Be specific and actionable\n",
    "    - Prioritize highest impact items\n",
    "    - Consider both immediate and long-term improvements\n",
    "    - Reference specific tasks or team members where relevant\n",
    "    - Suggest concrete steps for implementation\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        insights = response.content if hasattr(response, 'content') else str(response)\n",
    "        return {\"insights\": insights}\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating insights: {str(e)}\")\n",
    "        return {\"insights\": \"Unable to generate insights due to an error.\"}\n",
    "def risk_assessment_node(state: AgentState):\n",
    "    \"\"\"Langgraph node that analyses risk associated with schedule and allocation of task\"\"\"\n",
    "    schedule = state[\"schedule\"]\n",
    "    task_allocations = state[\"task_allocations\"]\n",
    "    previous_risks = state.get('risks_iteration', [])  # Use get() with default empty list\n",
    "    \n",
    "    prompt = f\"\"\"You are a seasoned project risk analyst tasked with evaluating the risks associated with the current project plan.\n",
    "    **Given:**\n",
    "        - **Task Allocations:** {task_allocations}\n",
    "        - **Schedule:** {schedule}\n",
    "        - **Previous Risk Assessments:** {previous_risks if previous_risks else 'No previous assessments'}\n",
    "    **Your objectives are to:**\n",
    "        1. **Assess Risks:**\n",
    "            - Analyze each allocated task and its scheduled timeline to identify potential risks.\n",
    "            - Consider factors such as task complexity, resource availability, and dependency constraints.\n",
    "        2. **Assign Risk Scores:**\n",
    "            - For each task, provide a risk assessment in the following JSON format:\n",
    "            {{\n",
    "                \"risks\": [\n",
    "                    {{\n",
    "                        \"task\": {{\n",
    "                            \"id\": \"task_uuid\",\n",
    "                            \"name\": \"task_name\",\n",
    "                            \"description\": \"task_description\",\n",
    "                            \"estimated_days\": number\n",
    "                        }},\n",
    "                        \"score\": \"number between 0-10\"\n",
    "                    }}\n",
    "                ]\n",
    "            }}\n",
    "            - Assign scores from 0 (no risk) to 10 (high risk)\n",
    "            - Consider previous risk scores for consistency if task assignments remain unchanged\n",
    "            - Lower scores for tasks with experienced team members\n",
    "            - Lower scores when there's adequate time between dependent tasks\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        structure_llm = llm.with_structured_output(RiskList)\n",
    "        risks: RiskList = structure_llm.invoke(prompt)\n",
    "        \n",
    "        # Calculate project risk score\n",
    "        project_risk_score = sum(int(risk.score) for risk in risks.risks)\n",
    "        \n",
    "        # Update state\n",
    "        state[\"risks\"] = risks\n",
    "        state[\"project_risk_score\"] = project_risk_score\n",
    "        state[\"iteration_number\"] += 1\n",
    "        state[\"project_risk_score_iterations\"].append(project_risk_score)\n",
    "        state[\"risks_iteration\"].append(risks)\n",
    "        \n",
    "        return state\n",
    "    except Exception as e:\n",
    "        print(f\"Error in risk assessment: {str(e)}\")\n",
    "        print(f\"Raw response from LLM: {risks if 'risks' in locals() else 'No response'}\")\n",
    "        # Return a default risk assessment\n",
    "        default_risks = RiskList(risks=[])\n",
    "        state[\"risks\"] = default_risks\n",
    "        state[\"project_risk_score\"] = 0\n",
    "        state[\"iteration_number\"] += 1\n",
    "        state[\"project_risk_score_iterations\"].append(0)\n",
    "        state[\"risks_iteration\"].append(default_risks)\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state:AgentState):\n",
    "    \"\"\"LangGraph node that will route the agent to the appropriate node based on the project description\"\"\"\n",
    "    max_iteration = state[\"max_iteration\"]\n",
    "    iteration_number = state[\"iteration_number\"]\n",
    "\n",
    "    if iteration_number < max_iteration:\n",
    "        if len(state[\"project_risk_score_iterations\"])>1:\n",
    "            if state[\"project_risk_score_iterations\"][-1] < state[\"project_risk_score_iterations\"][0]:\n",
    "                return END\n",
    "            else:\n",
    "                return \"insight_generator\"\n",
    "        else:\n",
    "            return \"insight_generator\"\n",
    "    else:\n",
    "        return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"task_generation\",task_generation_node)\n",
    "workflow.add_node(\"task_dependencies\",task_dependency_node)\n",
    "workflow.add_node(\"task_scheduler\",task_scheduler_node)\n",
    "workflow.add_node(\"task_allocator\",task_allocation_node)\n",
    "workflow.add_node(\"risk_assessor\",risk_assessment_node)\n",
    "workflow.add_node(\"insight_generator\",insight_generation_node)\n",
    "\n",
    "\n",
    "# Edges\n",
    "workflow.set_entry_point(\"task_generation\")\n",
    "workflow.add_edge(\"task_generation\", \"task_dependencies\")\n",
    "workflow.add_edge(\"task_dependencies\",\"task_scheduler\")\n",
    "workflow.add_edge(\"task_scheduler\",\"task_allocator\")\n",
    "workflow.add_edge(\"task_allocator\",\"risk_assessor\")\n",
    "workflow.add_conditional_edges(\"risk_assessor\",router,[\"insight_generator\",END])\n",
    "workflow.add_edge(\"insight_generator\",\"task_scheduler\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph_plan = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(\n",
    "    Image(\n",
    "        graph_plan.get_graph(xray=1).draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage\n",
    "Project Manager Agent requires a project description (str) and a team (Team) iput next to other initialization parameters. The team is defined as a csv file, composed of 2 columns : Name, Profile Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: AI-Powered Customer Support Chatbot Development\n",
      "\n",
      "Project Overview:\n",
      "Our business aims to develop and deploy an advanced AI-powered chatbot application to provide 24/7 customer support and product recommendations. This chatbot will serve as a virtual assistant to enhance customer experience and reduce support team workload.\n",
      "\n",
      "Key Requirements:\n",
      "1. Natural Language Processing capabilities to understand customer queries\n",
      "2. Integration with existing product database and customer support knowledge base\n",
      "3. Real-time product recommendations based on customer preferences\n",
      "4. Multi-platform support (website, mobile app, messaging platforms)\n",
      "5. Analytics dashboard for monitoring chatbot performance\n",
      "6. Secure handling of customer data and conversations\n",
      "\n",
      "Technical Specifications:\n",
      "- Backend: Python-based architecture with modern AI/ML frameworks\n",
      "- Frontend: Responsive web interface and mobile-friendly design\n",
      "- Database: Scalable solution for storing conversation history and analytics\n",
      "- API Integration: RESTful APIs for third-party service integration\n",
      "- Security: Industry-standard encryption and data protection measures\n",
      "\n",
      "Expected Deliverables:\n",
      "1. Fully functional chatbot with NLP capabilities\n",
      "2. Admin panel for managing chatbot responses and training\n",
      "3. Analytics dashboard for performance monitoring\n",
      "4. Documentation for maintenance and future updates\n",
      "5. Training materials for support team\n",
      "6. API documentation for future integrations\n",
      "\n",
      "Additional Considerations:\n",
      "- Must handle multiple concurrent users\n",
      "- Response time should be under 2 seconds\n",
      "- 99.9% uptime requirement\n",
      "- Scalable architecture for future expansion\n",
      "- Regular backup and disaster recovery systems\n",
      "- Compliance with data protection regulations\n",
      "\n",
      "team_members=[TeamMember(name='Alice', profile='Alice is a Frontend Developer skilled in HTML CSS JavaScript and React.'), TeamMember(name='Bob', profile='Bob is a Backend Developer proficient in Python Django SQL and RESTful APIs.'), TeamMember(name='Charlie', profile='Charlie is a Project Manager experienced in Agile methodologies team leadership project planning and risk management.'), TeamMember(name='David', profile='David is a Full Stack Developer with expertise in both frontend (HTML CSS JavaScript) and backend (Node.js MongoDB) technologies.'), TeamMember(name='Eve', profile='Eve is a DevOps Engineer skilled in CI/CD pipelines Docker Kubernetes and cloud services like AWS and Azure.'), TeamMember(name='Frank', profile='Frank is a Junior Frontend Developer with knowledge in HTML CSS JavaScript and basic React.'), TeamMember(name='Grace', profile='Grace is a Senior Data Scientist with expertise in machine learning data analysis Python R and big data technologies like Hadoop and Spark.')]\n"
     ]
    }
   ],
   "source": [
    "def get_project_description(file_path:str):\n",
    "    \"\"\"Read the project description from the txt file\"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    return content\n",
    "\n",
    "def get_team(file_path:str):\n",
    "    \"\"\"Read the team members name and description from csv file\"\"\"\n",
    "    team_df = pd.read_csv(file_path)\n",
    "    team_members = [\n",
    "        TeamMember(name=row['Name'],\n",
    "                   profile=row['Profile Description'])\n",
    "                   for _, row in team_df.iterrows()\n",
    "    ]\n",
    "    team = Team(team_members=team_members)\n",
    "    return team\n",
    "\n",
    "project_description = get_project_description('project_des.txt')\n",
    "team = get_team('team_members.csv')\n",
    "\n",
    "print(project_description)\n",
    "print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_input = {\n",
    "    \"project_description\": project_description,\n",
    "    \"team\":team,\n",
    "    \"insights\":\"\",\n",
    "    \"iteration_number\":0,\n",
    "    \"max_iteration\":3,\n",
    "    \"schedule_iteration\":[],\n",
    "    \"task_allocations_iteration\":[],\n",
    "    \"project_risk_score_iterations\":[],\n",
    "    \"risks_iteration\": [],\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current node: task_generation\n",
      "Error in dependency mapping: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool-use>\\n{\\n\\t\"tool_call\": {\\n\\t\\t\"id\": \"pending\",\\n\\t\\t\"type\": \"function\",\\n\\t\\t\"function\": {\\n\\t\\t\\t\"name\": \"DependencyList\"\\n\\t\\t},\\n\\t\\t\"parameters\": {\\n\\t\\t\\t\"dependencies\": [\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Define the scope and objectives of the AI-powered chatbot development project.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 2,\\n\\t\\t\\t\\t\\t\\t\"id\": \"19c585a1-01c7-45fb-84c9-359d70db00d8\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Project Scope Definition\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Conduct a thorough analysis of existing customer support channels and identify pain points.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 3,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"4cb829e8-ec96-4546-975e-71d723bd8196\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Customer Support Analysis\"\\n\\t\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Research and select suitable NLP libraries and frameworks for chatbot development.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 2,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"87258de9-ce53-41e1-8e9c-98459cf36d75\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"NLP Technology Selection\"\\n\\t\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Design the chatbot\\'s conversational flow and user interface.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 5,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"ba6b988b-49c9-462f-9cd0-5b6f5358978f\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Chatbot Design\"\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Conduct a thorough analysis of existing customer support channels and identify pain points.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 3,\\n\\t\\t\\t\\t\\t\\t\"id\": \"4cb829e8-ec96-4546-975e-71d723bd8196\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Customer Support Analysis\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \\'Integrate the chatbot with existing product database and customer support knowledge base.\\',\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 7,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"4c7259bf-19de-4024-a7b1-bdb923d18c17\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"API and Database Integration\"\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Research and select suitable NLP libraries and frameworks for chatbot development.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 2,\\n\\t\\t\\t\\t\\t\\t\"id\": \"87258de9-ce53-41e1-8e9c-98459cf36d75\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"NLP Technology Selection\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Develop the chatbot\\'s backend logic using Python and chosen AI/ML frameworks.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 15,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"7c87e8d4-f7d4-4b39-9909-04dfdb04bb0c\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Backend Development\"\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Design the chatbot\\'s conversational flow and user interface.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 5,\\n\\t\\t\\t\\t\\t\\t\"id\": \"ba6b988b-49c9-462f-9cd0-5b6f5358978f\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Chatbot Design\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Build the chatbot\\'s frontend interface for website and mobile app integration.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 10,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"d441d6dc-3359-4cd4-a243-1f15926cd107\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Frontend Development\"\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Develop the chatbot\\'s backend logic using Python and chosen AI/ML frameworks.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 15,\\n\\t\\t\\t\\t\\t\\t\"id\": \"7c87e8d4-f7d4-4b39-9909-04dfdb04bb0c\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Backend Development\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\\'description\\': \\'Integrate the chatbot with existing product database and customer support knowledge base.\\',\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 7,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"4c7259bf-19de-4024-a7b1-bdb923d18c17\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"API and Database Integration\"\\n\\t\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Conduct thorough testing of the chatbot across various platforms and scenarios.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 7,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"0edba5e0-3e3f-41fd-a146-df71c7b56af3\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Chatbot Testing\"\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \\'Integrate the chatbot with existing product database and customer support knowledge base.\\',\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 7,\\n\\t\\t\\t\\t\\t\\t\"id\": \"4c7259bf-19de-4024-a7b1-bdb923d18c17\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"API and Database Integration\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Develop the chatbot\\'s backend logic using Python and chosen AI/ML frameworks.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 15,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"7c87e8d4-f7d4-4b39-9909-04dfdb04bb0c\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Backend Development\"\\n\\t\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Build the chatbot\\'s frontend interface for website and mobile app integration.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 10,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"d441d6dc-3359-4cd4-a243-1f15926cd107\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Frontend Development\"\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Build the chatbot\\'s frontend interface for website and mobile app integration.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 10,\\n\\t\\t\\t\\t\\t\\t\"id\": \"d441d6dc-3359-4cd4-a243-1f15926cd107\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Frontend Development\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Conduct thorough testing of the chatbot across various platforms and scenarios.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 7,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"0edba5e0-3e3f-41fd-a146-df71c7b56af3\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Chatbot Testing\"\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Develop the chatbot\\'s backend logic using Python and chosen AI/ML frameworks.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 15,\\n\\t\\t\\t\\t\\t\\t\"id\": \"7c87e8d4-f7d4-4b39-9909-04dfdb04bb0c\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Backend Development\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Develop a robust analytics dashboard to monitor chatbot performance.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 5,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"b1b7f355-02e5-4c7d-8885-dd07654b64bc\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Analytics Dashboard Development\"\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Conduct thorough testing of the chatbot across various platforms and scenarios.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 7,\\n\\t\\t\\t\\t\\t\\t\"id\": \"0edba5e0-3e3f-41fd-a146-df71c7b56af3\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Chatbot Testing\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"description\": \"Train the support team on using the chatbot and addressing any issues.\",\\n\\t\\t\\t\\t\\t\\t\\t\"estimated_day\": 2,\\n\\t\\t\\t\\t\\t\\t\\t\"id\": \"6c6afa0a-64dc-4a92-9fa4-3279463559c0\",\\n\\t\\t\\t\\t\\t\\t\\t\"task_name\": \"Support Team Training\"\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Develop a robust analytics dashboard to monitor chatbot performance.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 5,\\n\\t\\t\\t\\t\\t\\t\"id\": \"b1b7f355-02e5-4c7d-8885-dd07654b64bc\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Analytics Dashboard Development\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": []\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Train the support team on using the chatbot and addressing any issues.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 2,\\n\\t\\t\\t\\t\\t\\t\"id\": \"6c6afa0a-64dc-4a92-9fa4-3279463559c0\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Support Team Training\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": []\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Create comprehensive documentation for chatbot maintenance and future updates.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 3,\\n\\t\\t\\t\\t\\t\\t\"id\": \"d739b071-8c71-441a-88c0-ec18270274fd\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Documentation\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": []\\n\\t\\t\\t\\t},\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\"task\": {\\n\\t\\t\\t\\t\\t\\t\"description\": \"Implement security measures to protect customer data and conversations.\",\\n\\t\\t\\t\\t\\t\\t\"estimated_day\": 3,\\n\\t\\t\\t\\t\\t\\t\"id\": \"e79fb215-0ee0-4541-a2c1-b86c0575d5e5\",\\n\\t\\t\\t\\t\\t\\t\"task_name\": \"Security Implementation\"\\n\\t\\t\\t\\t\\t},\\n\\t\\t\\t\\t\\t\"dependent_task\": []\\n\\t\\t\\t\\t}\\n\\t\\t\\t]\\n\\t\\t}\\n\\t}\\n}\\n</tool-use>\\n\\n'}}\n",
      "Raw response from LLM: No response\n",
      "Current node: task_dependencies\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfigurable\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m}}\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph_plan\u001b[38;5;241m.\u001b[39mstream(state_input,config,stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint the different nodes as the agent progresses\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent node: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(event[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:1649\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1644\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1645\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1646\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1649\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   1650\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m   1651\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   1652\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[0;32m   1653\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   1654\u001b[0m         ):\n\u001b[0;32m   1655\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   1657\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langgraph\\pregel\\runner.py:105\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    103\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langgraph\\pregel\\retry.py:44\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, writer)\u001b[0m\n\u001b[0;32m     42\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langgraph\\utils\\runnable.py:410\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[5], line 126\u001b[0m, in \u001b[0;36mtask_scheduler_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     structure_llm \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mwith_structured_output(Schedule)\n\u001b[1;32m--> 126\u001b[0m     schedule: Schedule \u001b[38;5;241m=\u001b[39m \u001b[43mstructure_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschedule\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m schedule\n\u001b[0;32m    128\u001b[0m     state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mschedule_iteration\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(schedule)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5355\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5356\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5357\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5358\u001b[0m     )\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\langchain_groq\\chat_models.py:474\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    470\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    473\u001b[0m }\n\u001b[1;32m--> 474\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(messages\u001b[38;5;241m=\u001b[39mmessage_dicts, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\groq\\resources\\chat\\completions.py:298\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\groq\\_base_client.py:1263\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1251\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1259\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1260\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1261\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1262\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\groq\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\groq\\_base_client.py:991\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 991\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    992\u001b[0m         request,\n\u001b[0;32m    993\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    995\u001b[0m     )\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    997\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    100\u001b[0m     (\n\u001b[0;32m    101\u001b[0m         http_version,\n\u001b[0;32m    102\u001b[0m         status,\n\u001b[0;32m    103\u001b[0m         reason_phrase,\n\u001b[0;32m    104\u001b[0m         headers,\n\u001b[0;32m    105\u001b[0m         trailing_data,\n\u001b[1;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\httpcore\\_backends\\sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\programming exe\\Python 3.10.11\\lib\\ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32mD:\\programming exe\\Python 3.10.11\\lib\\ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\":\"1\"}}\n",
    "for event in graph_plan.stream(state_input,config,stream_mode=[\"updates\"]):\n",
    "    \"print the different nodes as the agent progresses\"\n",
    "    print(f\"Current node: {next(iter(event[1]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ^^^ The errors due to incompatible output provided by llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "final_state = graph_plan.get_state(config).values\n",
    "print(final_state['iteration_number'])\n",
    "print(final_state['project_risk_score_iterations'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "task",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m t \u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task_allocation \u001b[38;5;129;01min\u001b[39;00m task_allocations:\n\u001b[0;32m     21\u001b[0m     t\u001b[38;5;241m.\u001b[39mappend([\n\u001b[1;32m---> 22\u001b[0m         \u001b[43mTaskAllocation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241m.\u001b[39mtask_name,\n\u001b[0;32m     23\u001b[0m         task_allocation\u001b[38;5;241m.\u001b[39mteam_member\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m     24\u001b[0m     ])\n\u001b[0;32m     26\u001b[0m df_allocation \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(t,columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask_name\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteam_member\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m df \u001b[38;5;241m=\u001b[39m df_allocation\u001b[38;5;241m.\u001b[39mmerge(df_schedule,on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtask_name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Coding\\Python\\GenAI Projects\\RAG Chatbot\\myenv\\lib\\site-packages\\pydantic\\_internal\\_model_construction.py:320\u001b[0m, in \u001b[0;36mModelMetaclass.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m private_attributes \u001b[38;5;129;01mand\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m private_attributes:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m private_attributes[item]\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(item)\n",
      "\u001b[1;31mAttributeError\u001b[0m: task"
     ]
    }
   ],
   "source": [
    "number_of_iter = final_state['iteration_number']\n",
    "\n",
    "for i in range(number_of_iter):\n",
    "    task_schedules = final_state['schedule_iteration'][i].schedule\n",
    "\n",
    "    t = []\n",
    "    for task_schedule in task_schedules:\n",
    "        t.append([\n",
    "            task_schedule.task.task_name,\n",
    "            task_schedule.start_day,\n",
    "            task_schedule.end_day\n",
    "        ])\n",
    "\n",
    "    df_schedule = pd.DataFrame(t,columns=['task_name','start','end'])\n",
    "\n",
    "    task_allocations = final_state['task_allocations_iteration'][i].task_allocations\n",
    "\n",
    "    t =[]\n",
    "\n",
    "    for task_allocation in task_allocations:\n",
    "        t.append([\n",
    "            TaskAllocation.task.task_name,\n",
    "            task_allocation.team_member.name\n",
    "        ])\n",
    "\n",
    "    df_allocation = pd.DataFrame(t,columns=['task_name','team_member'])\n",
    "\n",
    "    df = df_allocation.merge(df_schedule,on = 'task_name')\n",
    "\n",
    "    import plotly.express as px\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    current_date = datetime.today()\n",
    "\n",
    "    df['start'] = df['start'].apply(lambda x:current_date + timedelta(days=x))\n",
    "    df['end'] = df['end'].apply(lambda x:current_date + timedelta(days=x))\n",
    "    \n",
    "    df.rename(columns={'team_members':'Team Member'},inplace=True)\n",
    "    df.sort_values(by='Team Member',inplace=True)\n",
    "\n",
    "    fig = px.timeline(df, x_start='start',x_end='end',y='task_name', color = 'Team Member', title=f\"Gantt Chart - Iteration:{i+1}\")\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Timeline\",\n",
    "        yaxis_title=\"Tasks\",\n",
    "        yaxis=dict(autorange=\"reversed\"),\n",
    "        title_x=0.5\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Due to the llm not being good we are not getting the results as we are expecting (which is how we described in the prompt) and due to that the pydantic validation is giving error.\n",
    "\n",
    "If we use a good llm like openai's o1 model we can get good results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
